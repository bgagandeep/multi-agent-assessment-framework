<!DOCTYPE html>
<html lang="en">
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>Multi-Agent Assessment Framework Comparison</title>
    <style>
        body {
            font-family: Arial, sans-serif;
            line-height: 1.6;
            margin: 0;
            padding: 20px;
            color: #333;
            max-width: 1200px;
            margin: 0 auto;
        }
        h1 {
            color: #2c3e50;
            text-align: center;
            margin-bottom: 30px;
        }
        h2 {
            color: #3498db;
            margin-top: 30px;
        }
        .image-container {
            margin: 30px 0;
            text-align: center;
        }
        img {
            max-width: 100%;
            height: auto;
            box-shadow: 0 4px 8px rgba(0, 0, 0, 0.1);
        }
        .summary {
            background-color: #f9f9f9;
            padding: 20px;
            border-radius: 5px;
            margin: 30px 0;
        }
        .footer {
            text-align: center;
            margin-top: 50px;
            font-size: 0.9em;
            color: #7f8c8d;
        }
    </style>
</head>
<body>
    <h1>Multi-Agent Assessment Framework Comparison</h1>
    
    <div class="summary">
        <h2>Summary of Results</h2>
        <p>This report presents a comparison of different multi-agent frameworks for the article writing use case. The comparison includes execution time, token usage, and cost metrics for each framework.</p>
        <p>The frameworks compared are:</p>
        <ul>
            <li><strong>AutoGen</strong> - Not installed in this environment</li>
            <li><strong>Semantic Kernel</strong> - Microsoft's framework for building AI applications</li>
            <li><strong>LangChain</strong> - A popular framework for building LLM-powered applications</li>
            <li><strong>CrewAI</strong> - A framework for orchestrating role-playing autonomous AI agents</li>
        </ul>
    </div>

    <h2>Comparison Table</h2>
    <div class="image-container">
        <img src="framework_comparison_table.png" alt="Framework Comparison Table">
    </div>

    <h2>Visual Comparison</h2>
    <div class="image-container">
        <img src="framework_comparison.png" alt="Framework Comparison Charts">
    </div>

    <div class="summary">
        <h2>Key Findings</h2>
        <ul>
            <li><strong>Execution Time:</strong> LangChain took the longest time (109.81s), while Semantic Kernel (88.09s) and CrewAI (94.30s) were faster.</li>
            <li><strong>Token Usage:</strong> LangChain used the most tokens (8,270), followed by Semantic Kernel (7,721), while CrewAI used significantly fewer tokens (974).</li>
            <li><strong>Cost:</strong> LangChain was the most expensive ($0.0554), followed by Semantic Kernel ($0.0486), while CrewAI was much more cost-effective ($0.0094).</li>
        </ul>
        <p><strong>Overall:</strong> CrewAI demonstrated the best balance of performance, using significantly fewer tokens while still delivering quality results in a reasonable time frame, making it the most cost-effective option for this use case.</p>
    </div>

    <div class="footer">
        <p>Generated using the Multi-Agent Assessment Framework</p>
        <p>Date: March 5, 2024</p>
    </div>
</body>
</html> 